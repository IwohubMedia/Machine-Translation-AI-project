# Machine Translation with Seq2Seq + Attention

This project implements a sequence-to-sequence neural machine translation (NMT) model with attention using PyTorch.  
The model is trained on the **Multi30k English â†” German dataset**.

---

## ðŸš€ How to Run

1. Open the [Colab notebook](https://colab.research.google.com/)  
2. Click **Runtime > Run all**  
3. The model will train and save as `seq2seq_attention.pth`  
4. You can find the saved model under the Colab **Files** tab.  
5. To install dependencies:
   ```bash
   pip install -r requirements.txt
